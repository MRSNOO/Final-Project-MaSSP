# -*- coding: utf-8 -*-
"""Copy of mtcnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KBNJjZi6F-4m0qC9Sx6cXx8F-Nf_6m5f
"""

!pip3 install mtcnn
!pip3 install tensorflow-gpu
!pip3 install tensorflow opencv-contrib-python

!pip install git+https://github.com/ageitgey/face_recognition_models

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import imageio
from matplotlib import pyplot as plt
from mtcnn.mtcnn import MTCNN
import os
import PIL.Image
import dlib
from PIL import ImageFile
from PIL import Image
import cv2
import face_recognition_models
from sklearn import neighbors

class FaceRecognizer:
  
  ImageFile.LOAD_TRUNCATED_IMAGES = True

  
  predictor_68_point_model = face_recognition_models.pose_predictor_model_location()
  pose_predictor_68_point = dlib.shape_predictor(predictor_68_point_model)

  face_recognition_model = face_recognition_models.face_recognition_model_location()
  face_encoder = dlib.face_recognition_model_v1(face_recognition_model)
  
  detector = MTCNN()
  
  def __init__ (self):
    self.clf = None
    return
  
  def img_load(self,img_dir):
    img = imageio.imread(img_dir)
    img = np.asarray(img)
    return img
  
  def _raw_face_landmarks(self, face_image, face_locations=None, model="large"):
    pose_predictor = self.pose_predictor_68_point
    return [pose_predictor(face_image, face_location) for face_location in face_locations]


  def face_encodings(self, face_image, known_face_locations=None, num_jitters=2):
    """
    Given an image, return the 128-dimension face encoding for each face in the image.
    :param face_image: The image that contains one or more faces
    :param known_face_locations: Optional - the bounding boxes of each face if you already know them.
    :param num_jitters: How many times to re-sample the face when calculating encoding. Higher is more accurate, but slower (i.e. 100 is 100x slower)
    :return: A list of 128-dimensional face encodings (one for each face in the image)
    """
    raw_landmarks = self._raw_face_landmarks(face_image, known_face_locations)
    return [np.array(self.face_encoder.compute_face_descriptor(face_image, raw_landmark_set, num_jitters)) for raw_landmark_set in raw_landmarks]
  
  
  def predict_and_encode (self, img, confidence = 0.9,ratio = 30,visua = False):
    predict = self.detector.detect_faces(img)
    #print(predict)
    out_boxes = [ item['box'] for item in predict if item["confidence"]> confidence and item["box"][3]>img.shape[0]/ratio]
    out_boxes = dlib.rectangles([dlib.rectangle(a,b,a+c,b+d) for a,b,c,d in out_boxes ])
    #print(out_boxes)
    key = [item['keypoints'] for item in predict if item["confidence"]> confidence and item["box"][3]>img.shape[0]/ratio]
    img_encoded = self.face_encodings(img,out_boxes)
    #print(key)
    if visua:
      self.visualize(img,out_boxes,key)
    return out_boxes, key, img_encoded
  
  
  def visualize(self, img,out_boxes,key,name = []):
    img2 = img.copy()
    plt.figure(figsize=(15, 15))
    for i, c in list(enumerate(out_boxes)):
      box = out_boxes[i]
      cv2.rectangle(img2,(box.left(),box.top()),(box.right(),box.bottom()),(0,255,0),int(img.shape[1]/150))
      if len(name) != 0:
        plt.text(box.left(),box.top(),name[i],fontsize = img.shape[0]/50, color = 'red')
      keyx = [item[0] for item in key[i].values()]
      keyy = [item[1] for item in key[i].values()]
      #print(keyx,keyy)
      #plt.plot(keyx,keyy,'bo')
    plt.axis('off')
    plt.imshow(img2)
    #plt.savefig("/content/drive/My Drive/predict.png", bbox_inches='tight', pad_inches=0)
    plt.show()
  def init_KNN(self, X_train, y_train):
    clf = neighbors.KNeighborsClassifier(n_neighbors = 15, p = 2, weights = 'distance', n_jobs = -1)
    clf.fit(X_train, y_train)
    self.clf = clf
  def search_face(self, img):
    out_boxes, key, img_encoded = self.predict_and_encode (img)
    print(len(img_encoded))
    if len(img_encoded)==0:
      print("can not search")
    else:
      results = self.clf.predict(img_encoded)
      score = self.clf.predict_proba(img_encoded)
      print(results)
      #print(score)
      final_results = []
      for i in range (len(results)):
        if max(score[i])>0.8:
          final_results.append(results[i])
        else:
          final_results.append("unknown")
      print(final_results)
      self.visualize(img,out_boxes,key,final_results)
    
Detector = FaceRecognizer()

Detector.init_KNN(X_train, y_train)

print(type(X_train))
print(type(X_train[0]))
print(type(y_train))
print(len(X_train))

fn = "/content/drive/My Drive/Video/test"
#for image in os.listdir(fn):
for image in ["test.jpg"]:
  img = Detector.img_load(fn + "/" + str(image))
  Detector.search_face(img)
  #out_boxes,key,img_encoded = Detector.predict_and_encode (img,visua = True)
  #print (out_boxes)

fn = "/content/drive/My Drive/Video/dataset"
X_train = []
y_train = []
for i,person in list(enumerate(os.listdir(fn))):
  for image in os.listdir(fn+'/'+str(person)):
    print(person, ": ",image)
    img = Detector.img_load(fn + '/' + str(person) + "/" + str(image))
    out_boxes, key, img_encoded = Detector.predict_and_encode (img)
    if len(img_encoded)==1:
      X_train.append(img_encoded[0])
      y_train.append(person)

# save X_train y_train to a .scv file for fulture use
import pandas as pd
fn = "/content/drive/My Drive/"
df = pd.DataFrame({"result": y_train})
for i in range(128):
  df = df.join(pd.DataFrame({("encode"+str(i)): [code[i] for code in X_train]}))
df.to_csv(fn+'train_data.csv', index=False)

#load X_train y_train from .scv file for fulture use
import pandas as pd
fn = "/content/drive/My Drive/train_data.csv"
df = pd.read_csv(fn)
X_train = []
y_train = []
for i in range(df.shape[0]):
  img = np.array(df.iloc[i])
  X_train.append(img[1:])
  y_train.append(img[0])
#print (X_train[0:5])
#print (y_train)
print(type(X_train))
print(len(X_train))
print(type(X_train[0]))
print(type(y_train))

for imgname in ['Nhi2.jpg']:
  img = Detector.img_load("/content/drive/My Drive/test/"+str(imgname))
  out_boxes,key,img_encoded = Detector.predict_and_encode (img,visua = True)
